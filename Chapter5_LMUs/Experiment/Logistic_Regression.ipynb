{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nengo\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data without LMU Preprocessing as Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleLR_raw(run):\n",
    "    \n",
    "    data_dir = \"./LR_Raw/\"\n",
    "    if run == 0:\n",
    "        os.mkdir(data_dir)\n",
    "    \n",
    "    highdata_raw = np.load('higheng.npy',allow_pickle=True)\n",
    "    lowdata_raw = np.load('loweng.npy',allow_pickle=True)\n",
    "    middata_raw = np.load('mideng.npy',allow_pickle=True)\n",
    "    randdata_raw=np.load('rand_data.npy',allow_pickle=True)\n",
    "\n",
    "    high=list(highdata_raw[:,1])\n",
    "    low=list(lowdata_raw[:,1])\n",
    "    mid_test=list(middata_raw[:,1])\n",
    "    rand_data=list(randdata_raw)\n",
    "\n",
    "    #shuffle clips\n",
    "    np.random.shuffle(high)\n",
    "    np.random.shuffle(low)\n",
    "    np.random.shuffle(mid_test)\n",
    "    np.random.shuffle(rand_data)\n",
    "\n",
    "    #get training clips and convert to list of frames\n",
    "    high_train = high[:(int(len(low)*0.7))]\n",
    "    high_train=list(np.vstack(high_train))\n",
    "    low_train = low[:(int(len(low)*0.7))]\n",
    "    low_train=list(np.vstack(low_train))\n",
    "\n",
    "    #shuffle frames\n",
    "    np.random.shuffle(high_train)\n",
    "    np.random.shuffle(low_train)\n",
    "\n",
    "    #Make each training set same size (noplay is shortest)\n",
    "    high_train = high_train[:(int(len(low_train)))]\n",
    "    low_train = low_train[:(int(len(low_train)))]\n",
    "\n",
    "    #Create test sets\n",
    "    high_test = high[(int(len(low)*0.7)):(int(len(low)*0.9))]\n",
    "    low_test = low[(int(len(low)*0.7)):(int(len(low)*0.9))]\n",
    "    rand_test = rand_data[:18]\n",
    "\n",
    "    np.random.shuffle(high_test)\n",
    "    np.random.shuffle(low_test)\n",
    "    np.random.shuffle(mid_test)\n",
    "    np.random.shuffle(rand_test)\n",
    "\n",
    "    all_train = np.vstack(np.concatenate((high_train, low_train)))\n",
    "    all_test = np.concatenate((high_test, mid_test, low_test, rand_test)) \n",
    "\n",
    "    pickle_filename = (data_dir+\"/%s_train_data.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(all_train, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_test_data.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(all_test, file)\n",
    "\n",
    "    #create the target data for training\n",
    "    target_train = np.zeros((all_train.shape[0],1))\n",
    "    n_high = len(high_train)\n",
    "    target_train[:n_high,0] = 1\n",
    "    target_train[n_high:,0] = -1\n",
    "\n",
    "    #and for testing\n",
    "    target_test = np.zeros((all_test.shape[0],1))\n",
    "    n_high = len(high_test)\n",
    "    n_mid = n_high + len(mid_test)\n",
    "    n_low = n_mid + len(low_test)\n",
    "    target_test[:n_high,0] = 1\n",
    "    target_test[n_high:n_mid,0] = 0\n",
    "    target_test[n_mid:n_low,0] = -1\n",
    "    target_test[n_low:,0] = 0 #np.random.rand()\n",
    "    \n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    classifier.fit(all_train, target_train)\n",
    "\n",
    "    y_pred=[]\n",
    "    decision=[]\n",
    "    prob=[]\n",
    "    for i in all_test:\n",
    "        y_pred.append(classifier.predict(i))\n",
    "        decision.append(classifier.decision_function(i))\n",
    "        prob.append(classifier.predict_proba(i))\n",
    "\n",
    "    pickle_filename = (data_dir+\"/%s_test_out.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(y_pred, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_decision.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(decision, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_prob.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(prob, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_test_target.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(target_test, file)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(20):\n",
    "    classifier = simpleLR_raw(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMU Preprocessed Data as Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleLR_lmu(run):\n",
    "    \n",
    "    data_dir = \"./LR_LMU/\"\n",
    "    if run == 0:\n",
    "        os.mkdir(data_dir)\n",
    "    \n",
    "    highdata_lmu = np.load('high_lmu4_theta3.npy',allow_pickle=True)\n",
    "    lowdata_lmu = np.load('low_lmu4_theta3.npy',allow_pickle=True)\n",
    "    middata_lmu = np.load('mid_lmu4_theta3.npy',allow_pickle=True)\n",
    "    rand_lmu = np.load('rand_lmu4_theta3.npy', allow_pickle=True)\n",
    "    \n",
    "    high=list(highdata_lmu[:])\n",
    "    low=list(lowdata_lmu[:])\n",
    "    mid_test=list(middata_lmu[:])\n",
    "    rand_data=list(rand_lmu)\n",
    "\n",
    "    #shuffle clips\n",
    "    np.random.shuffle(high)\n",
    "    np.random.shuffle(low)\n",
    "    np.random.shuffle(mid_test)\n",
    "    np.random.shuffle(rand_data)\n",
    "\n",
    "    #get training clips and convert to list of frames\n",
    "    high_train = high[:(int(len(low)*0.7))]\n",
    "    high_train=list(np.vstack(high_train))\n",
    "    low_train = low[:(int(len(low)*0.7))]\n",
    "    low_train=list(np.vstack(low_train))\n",
    "\n",
    "    #shuffle frames\n",
    "    np.random.shuffle(high_train)\n",
    "    np.random.shuffle(low_train)\n",
    "\n",
    "    #Make each training set same size (noplay is shortest)\n",
    "    high_train = high_train[:(int(len(low_train)))]\n",
    "    low_train = low_train[:(int(len(low_train)))]\n",
    "\n",
    "    #Create test sets\n",
    "    high_test = high[(int(len(low)*0.7)):(int(len(low)*0.9))]\n",
    "    low_test = low[(int(len(low)*0.7)):(int(len(low)*0.9))]\n",
    "    rand_test = rand_data[:18]\n",
    "\n",
    "    np.random.shuffle(high_test)\n",
    "    np.random.shuffle(low_test)\n",
    "    np.random.shuffle(mid_test)\n",
    "    np.random.shuffle(rand_test)\n",
    "\n",
    "    all_train = np.vstack(np.concatenate((high_train, low_train)))\n",
    "    all_test = np.concatenate((high_test, mid_test, low_test, rand_test))\n",
    "    \n",
    "    pickle_filename = (data_dir+\"/%s_train_data.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(all_train, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_test_data.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(all_test, file)\n",
    "\n",
    "    #create the target data for training\n",
    "    target_train = np.zeros((all_train.shape[0],1))\n",
    "    n_high = len(high_train)\n",
    "    target_train[:n_high,0] = 1\n",
    "    target_train[n_high:,0] = -1\n",
    "\n",
    "    #and for testing\n",
    "    target_test = np.zeros((all_test.shape[0],1))\n",
    "    n_high = len(high_test)\n",
    "    n_mid = n_high + len(mid_test)\n",
    "    n_low = n_mid + len(low_test)\n",
    "    target_test[:n_high,0] = 1\n",
    "    target_test[n_high:n_mid,0] = 0\n",
    "    target_test[n_mid:n_low,0] = -1\n",
    "    target_test[n_low:,0] = 0 #np.random.rand()   \n",
    "    \n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    classifier.fit(all_train, target_train)\n",
    "\n",
    "    y_pred=[]\n",
    "    decision=[]\n",
    "    prob=[]\n",
    "    accuracy=[]\n",
    "    for i in all_test:\n",
    "        y_pred.append(classifier.predict(i))\n",
    "        decision.append(classifier.decision_function(i))\n",
    "        prob.append(classifier.predict_proba(i))\n",
    "\n",
    "    pickle_filename = (data_dir+\"/%s_test_out.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(y_pred, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_decision.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(decision, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_prob.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(prob, file)\n",
    "        \n",
    "    pickle_filename = (data_dir+\"/%s_test_target.pkl\") % str(run)\n",
    "    with open(pickle_filename, 'wb') as file:\n",
    "        pickle.dump(target_test, file)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(20):\n",
    "    classifier = simpleLR_lmu(run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
