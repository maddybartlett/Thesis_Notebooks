{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import nengo\n",
    "\n",
    "from scipy.special import legendre\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Random Data\n",
    "Replace every value in the high engagement dataset with a random value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = np.load('higheng.npy',allow_pickle=True)\n",
    "high = high[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "for i in range(len(high)):\n",
    "    for j in range(len(high[i])):\n",
    "        for k in range(len(high[i][j])):\n",
    "            high[i][j][k]=np.random.rand()\n",
    "np.save('rand_data.npy', high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LMU Pre-processed Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaron's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a nengo.Process that implements an LMU.  This can be placed inside a\n",
    "#  nengo.Node\n",
    "class Legendre(nengo.Process):\n",
    "    def __init__(self, theta, q, size_in=1):\n",
    "        self.q = q              # number of internal state dimensions per input\n",
    "        self.theta = theta      # size of time window (in seconds)\n",
    "        self.size_in = size_in  # number of inputs\n",
    "        \n",
    "        # Do Aaron's math to generate the matrices\n",
    "        #  https://github.com/arvoelke/nengolib/blob/master/nengolib/synapses/analog.py#L536\n",
    "        Q = np.arange(q, dtype=np.float64)\n",
    "        R = (2*Q + 1)[:, None] / theta\n",
    "        j, i = np.meshgrid(Q, Q)\n",
    "    \n",
    "        self.A = np.where(i < j, -1, (-1.)**(i-j+1)) * R\n",
    "        self.B = (-1.)**Q[:, None] * R\n",
    "\n",
    "        super().__init__(default_size_in=size_in, default_size_out=q*size_in)\n",
    "        \n",
    "    def make_step(self, shape_in, shape_out, dt, rng, state=None):\n",
    "        state=np.zeros((self.q, self.size_in))\n",
    "        \n",
    "        # Handle the fact that we're discretizing the time step\n",
    "        #  see https://en.wikipedia.org/wiki/Discretization#Discretization_of_linear_state_space_models\n",
    "        Ad = scipy.linalg.expm(self.A*dt)\n",
    "        Bd = np.dot(np.dot(np.linalg.inv(self.A), (Ad-np.eye(self.q))), self.B)\n",
    "        \n",
    "        # this code will be called every timestep\n",
    "        def step_legendre(t, x, state=state):\n",
    "            state[:] = np.dot(Ad, state) + np.dot(Bd, x[None,:])\n",
    "            return state.T.flatten()\n",
    "        return step_legendre\n",
    "\n",
    "    def get_weights_for_delays(self, r):\n",
    "        # compute the weights needed to extract the value at time r\n",
    "        # from the network (r=0 is right now, r=1 is theta seconds ago)\n",
    "        r = np.asarray(r)\n",
    "        m = np.asarray([legendre(i)(2*r - 1) for i in range(self.q)])\n",
    "        return m.reshape(self.q,-1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = np.load('higheng.npy',allow_pickle=True)\n",
    "high = high[:,1]\n",
    "\n",
    "mid = np.load('mideng.npy',allow_pickle=True)\n",
    "mid = mid[:,1]\n",
    "\n",
    "low = np.load('loweng.npy',allow_pickle=True)\n",
    "low = low[:,1]\n",
    "\n",
    "random = np.load('rand_data.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameters. <br>\n",
    "theta = length of time (seconds) \n",
    "q = convert every 1 value into q new values which characterises the input over the last theta seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 3\n",
    "q = 4\n",
    "dt = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data by subtracting clip mean and dividing by clip sd for each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=np.vstack(high)\n",
    "m=np.vstack(mid)\n",
    "l=np.vstack(low)\n",
    "r=np.vstack(random)\n",
    "\n",
    "#calculate mean and sd for high and low engagement combined\n",
    "hl_mean = np.vstack(np.concatenate((h,l))).mean(axis=0)\n",
    "hl_sd = np.vstack(np.concatenate((h,l))).std(axis=0)\n",
    "\n",
    "#calculate mean and sd for intermediate engagement separately\n",
    "m_mean = m.mean(axis=0) \n",
    "m_sd = m.std(axis=0) \n",
    "\n",
    "#calculate mean and sd for random data separately\n",
    "r_mean = r.mean(axis=0) \n",
    "r_sd = r.std(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize high engagement\n",
    "for h in high:\n",
    "    h -= hl_mean\n",
    "    h /= hl_sd\n",
    "\n",
    "#normalize low engagement\n",
    "for l in low:\n",
    "    l -= hl_mean\n",
    "    l /= hl_sd\n",
    "\n",
    "#normalize intermediate engagement\n",
    "for m in mid:\n",
    "    m -= m_mean\n",
    "    m /= m_sd\n",
    "    \n",
    "#normalize random data\n",
    "for r in random:\n",
    "    r -= r_mean\n",
    "    r /= r_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement LMU on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_lmu=[]\n",
    "\n",
    "for i in high:\n",
    "    lmu = Legendre(theta=theta, q=q, size_in=184)\n",
    "    y = lmu.apply(i, dt=dt) \n",
    "    decoder = lmu.get_weights_for_delays(0)\n",
    "    high_lmu.append(y)\n",
    "    \n",
    "high_lmu=np.asarray(high_lmu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_lmu=[]\n",
    "\n",
    "for i in mid:\n",
    "    lmu = Legendre(theta=theta, q=q, size_in=184)\n",
    "    y = lmu.apply(i, dt=dt) \n",
    "    decoder = lmu.get_weights_for_delays(0)\n",
    "    mid_lmu.append(y)\n",
    "    \n",
    "mid_lmu=np.asarray(mid_lmu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_lmu=[]\n",
    "\n",
    "for i in low:\n",
    "    lmu = Legendre(theta=theta, q=q, size_in=184)\n",
    "    y = lmu.apply(i, dt=dt) \n",
    "    decoder = lmu.get_weights_for_delays(0)\n",
    "    low_lmu.append(y)\n",
    "    \n",
    "low_lmu=np.asarray(low_lmu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lmu=[]\n",
    "\n",
    "for i in random:\n",
    "    lmu = Legendre(theta=theta, q=q, size_in=184)\n",
    "    y = lmu.apply(i, dt=dt) \n",
    "    decoder = lmu.get_weights_for_delays(0)\n",
    "    rand_lmu.append(y)\n",
    "    \n",
    "rand_lmu=np.asarray(rand_lmu)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('high_lmu'+str(q)+'_theta'+str(theta)+'.npy', high_lmu, allow_pickle=True)\n",
    "np.save('mid_lmu'+str(q)+'_theta'+str(theta)+'.npy', mid_lmu, allow_pickle=True)\n",
    "np.save('low_lmu'+str(q)+'_theta'+str(theta)+'.npy', low_lmu, allow_pickle=True)\n",
    "np.save('rand_lmu'+str(q)+'_theta'+str(theta)+'.npy', rand_lmu, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
