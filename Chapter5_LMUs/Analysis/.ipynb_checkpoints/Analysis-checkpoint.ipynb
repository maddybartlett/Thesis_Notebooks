{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pytry\n",
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from scipy import stats\n",
    "import researchpy as rp\n",
    "from scipy.stats import norm, ttest_ind, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "from math import sqrt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, classification_report, precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrraw = pd.read_pickle(\"../Data/Output/lrraw.pkl\") #logistic regression without lmus\n",
    "lrlmu = pd.read_pickle(\"../Data/Output/lrlmu.pkl\") #logistic regression with lmus\n",
    "mlpraw = pd.read_pickle(\"../Data/Output/mlpraw.pkl\") #mlp without lmus\n",
    "mlplmu = pd.read_pickle(\"../Data/Output/mlplmu.pkl\") #mlp without lmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Trained Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame-By-Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get classifier outputs for high and low engagement frames**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrraw_highframes=[]\n",
    "lrraw_lowframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(lrraw['prediction_prob_high'][i])\n",
    "    lrraw_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(lrraw['prediction_prob_low'][i])\n",
    "    lrraw_lowframes.append(b)\n",
    "    \n",
    "lrraw_highframes_all = np.vstack(lrraw_highframes)\n",
    "lrraw_lowframes_all = np.vstack(lrraw_lowframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrlmu_highframes=[]\n",
    "lrlmu_lowframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(lrlmu['prediction_prob_high'][i])\n",
    "    lrlmu_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(lrlmu['prediction_prob_low'][i])\n",
    "    lrlmu_lowframes.append(b)\n",
    "    \n",
    "lrlmu_highframes_all = np.vstack(lrlmu_highframes)\n",
    "lrlmu_lowframes_all = np.vstack(lrlmu_lowframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpraw_highframes=[]\n",
    "mlpraw_lowframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(mlpraw['decision_high'][i])\n",
    "    mlpraw_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(mlpraw['decision_low'][i])\n",
    "    mlpraw_lowframes.append(b)\n",
    "    \n",
    "mlpraw_highframes_all = np.vstack(mlpraw_highframes)\n",
    "mlpraw_lowframes_all = np.vstack(mlpraw_lowframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP with LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlplmu_highframes=[]\n",
    "mlplmu_lowframes=[]\n",
    "for i in range(20):\n",
    "    a=np.vstack(mlplmu['decision_high'][i])\n",
    "    mlplmu_highframes.append(a)\n",
    "    \n",
    "    b=np.vstack(mlplmu['decision_low'][i])\n",
    "    mlplmu_lowframes.append(b)\n",
    "    \n",
    "mlplmu_highframes_all = np.vstack(mlplmu_highframes)\n",
    "mlplmu_lowframes_all = np.vstack(mlplmu_lowframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we look at the distribution of classification values given to frames from each type of clip.** <br>\n",
    "Also calculate the percentage of frames which were given the correct classification. <br>\n",
    "For high engagement clips, correct = 1. <br>\n",
    "For low engagement, correct = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = classifier output, y-axis = count\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "outer = gridspec.GridSpec(2, 2)\n",
    "lrrplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[0])\n",
    "lrlplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[1])\n",
    "mlprplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[2])\n",
    "mlplplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[3])\n",
    "\n",
    "fig.text(0.29, 0.94, 'Logistic Regression', ha='center', fontsize=15)\n",
    "ax1 = fig.add_subplot(lrrplot[0, 0])\n",
    "ax1.hist(lrraw_highframes_all[:,1], bins=bins, color='black')\n",
    "ax1.title.set_text('High')\n",
    "ax1.set_ylabel('Count', fontsize=13)\n",
    "ax2 = fig.add_subplot(lrrplot[0, 1], sharey=ax1)\n",
    "ax2.hist(lrraw_lowframes_all[:,1], bins=bins, color='black')\n",
    "ax2.title.set_text('Low')\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.3, 0.51, 'Probability of High Engagement', ha='center', fontsize=13)\n",
    "\n",
    "fig.text(0.77, 0.94, 'Logistic Regression with LMUs', ha='center', fontsize=15)\n",
    "ax3 = fig.add_subplot(lrlplot[0, 0])\n",
    "ax3.hist(lrlmu_highframes_all[:,1], bins=bins, color='black')\n",
    "ax3.title.set_text('High')\n",
    "ax3.set_ylabel('Count', fontsize=13)\n",
    "ax4 = fig.add_subplot(lrlplot[0, 1], sharey=ax3)\n",
    "ax4.hist(lrlmu_lowframes_all[:,1], bins=bins, color='black')\n",
    "ax4.title.set_text('Low')\n",
    "plt.setp(ax4.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.77, 0.51, 'Probability of High Engagement', ha='center', fontsize=13)\n",
    "\n",
    "fig.text(0.29, 0.46, 'MLP', ha='center', fontsize=15)\n",
    "ax5 = fig.add_subplot(mlprplot[0, 0])\n",
    "ax5.hist(mlpraw_highframes_all, bins=bins, color='black')\n",
    "ax5.title.set_text('High')\n",
    "ax5.set_ylabel('Count', fontsize=13)\n",
    "ax6 = fig.add_subplot(mlprplot[0, 1], sharey=ax5)\n",
    "ax6.hist(mlpraw_lowframes_all, bins=bins, color='black')\n",
    "ax6.title.set_text('Low')\n",
    "plt.setp(ax6.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.29, 0.05, 'Decision Score', ha='center', fontsize=13)\n",
    "\n",
    "fig.text(0.77, 0.46, 'MLP with LMUs', ha='center', fontsize=15)\n",
    "ax7 = fig.add_subplot(mlplplot[0, 0])\n",
    "ax7.hist(mlplmu_highframes_all, bins=bins, color='black')\n",
    "ax7.title.set_text('High')\n",
    "ax7.set_ylabel('Count', fontsize=13)\n",
    "ax8 = fig.add_subplot(mlplplot[0, 1], sharey=ax7)\n",
    "ax8.hist(mlplmu_lowframes_all, bins=bins, color='black')\n",
    "ax8.title.set_text('Low')\n",
    "plt.setp(ax8.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.77, 0.05, 'Decision Score', ha='center', fontsize=13)\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "fig.text(0.07, 0.9, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.9, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.07, 0.44, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.44, 'D', ha='center', fontsize=15)\n",
    "\n",
    "fig.savefig('../Figs/framehist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate mean percent of high and low frames classified correctly by each approach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of how many frames were correctly classified in each experiment\n",
    "high_counts=[]\n",
    "low_counts=[]\n",
    "for i in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(lrraw['prediction_prob_high'][i]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    (nl, bins, plot) = ax2.hist(np.vstack(lrraw['prediction_prob_low'][i]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    \n",
    "high_cor = [item[1][9] for item in high_counts] #no. high frames classified correctly in each experiment\n",
    "high_len = [sum(item[1]) for item in high_counts] #no. high frames total in each experiment\n",
    "\n",
    "low_cor = [item[1][0] for item in low_counts] #no. low frames classified correctly in each experiment\n",
    "low_len = [sum(item[1]) for item in low_counts] #no. low frames total in each experiment\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "low_percent=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "lrrhigh_cor_mean=high_percent.mean()\n",
    "lrrhigh_cor_sd=high_percent.std()\n",
    "lrrlow_cor_mean=low_percent.mean()\n",
    "lrrlow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of how many frames were correctly classified in each experiment\n",
    "high_counts=[]\n",
    "low_counts=[]\n",
    "for i in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(lrlmu['prediction_prob_high'][i]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    (nl, bins, plot) = ax2.hist(np.vstack(lrlmu['prediction_prob_low'][i]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    \n",
    "high_cor = [item[1][9] for item in high_counts] #no. high frames classified correctly in each experiment\n",
    "high_len = [sum(item[1]) for item in high_counts] #no. high frames total in each experiment\n",
    "\n",
    "low_cor = [item[1][0] for item in low_counts] #no. low frames classified correctly in each experiment\n",
    "low_len = [sum(item[1]) for item in low_counts] #no. low frames total in each experiment\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "low_percent=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "lrlhigh_cor_mean=high_percent.mean()\n",
    "lrlhigh_cor_sd=high_percent.std()\n",
    "lrllow_cor_mean=low_percent.mean()\n",
    "lrllow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of how many frames were correctly classified in each experiment\n",
    "high_counts=[]\n",
    "low_counts=[]\n",
    "for i in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(mlpraw['decision_high'][i]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    (nl, bins, plot) = ax2.hist(np.vstack(mlpraw['decision_low'][i]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    \n",
    "high_cor = [item[9] for item in high_counts] #no. high frames classified correctly in each experiment\n",
    "high_len = [sum(item) for item in high_counts] #no. high frames total in each experiment\n",
    "\n",
    "low_cor = [item[0] for item in low_counts] #no. low frames classified correctly in each experiment\n",
    "low_len = [sum(item) for item in low_counts] #no. low frames total in each experiment\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "low_percent=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "mlprhigh_cor_mean=high_percent.mean()\n",
    "mlprhigh_cor_sd=high_percent.std()\n",
    "mlprlow_cor_mean=low_percent.mean()\n",
    "mlprlow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP with LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of how many frames were correctly classified in each experiment\n",
    "high_counts=[]\n",
    "low_counts=[]\n",
    "for i in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(mlplmu['decision_high'][i]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    (nl, bins, plot) = ax2.hist(np.vstack(mlplmu['decision_low'][i]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    \n",
    "high_cor = [item[9] for item in high_counts] #no. high frames classified correctly in each experiment\n",
    "high_len = [sum(item) for item in high_counts] #no. high frames total in each experiment\n",
    "\n",
    "low_cor = [item[0] for item in low_counts] #no. low frames classified correctly in each experiment\n",
    "low_len = [sum(item) for item in low_counts] #no. low frames total in each experiment\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "low_percent=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "mlplhigh_cor_mean=high_percent.mean()\n",
    "mlplhigh_cor_sd=high_percent.std()\n",
    "mlpllow_cor_mean=low_percent.mean()\n",
    "mlpllow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Percent_Correct_Frames = pd.DataFrame({'LR M(SD)': [f'{lrrhigh_cor_mean:.2f}'+'%'+' ('+f'{lrrhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{lrrlow_cor_mean:.2f}'+'%'+' ('+f'{lrrlow_cor_sd:.2f}'+')'],\n",
    "                                'LR with LMU M(SD)': [f'{lrlhigh_cor_mean:.2f}'+'%'+' ('+f'{lrlhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{lrllow_cor_mean:.2f}'+'%'+' ('+f'{lrllow_cor_sd:.2f}'+')'],\n",
    "                                'MLP M(SD)': [f'{mlprhigh_cor_mean:.2f}'+'%'+' ('+f'{mlprhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{mlprlow_cor_mean:.2f}'+'%'+' ('+f'{mlprlow_cor_sd:.2f}'+')'],\n",
    "                                'MLP with LMU M(SD)': [f'{mlplhigh_cor_mean:.2f}'+'%'+' ('+f'{mlplhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{mlpllow_cor_mean:.2f}'+'%'+' ('+f'{mlpllow_cor_sd:.2f}'+')']})\n",
    "\n",
    "Percent_Correct_Frames.set_index([pd.Index(['High Engagement', 'Low Engagement'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip-Wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and Collect Summary Statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression without LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of probability of high engagement classification over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(lrraw)):\n",
    "    for i in range(18):\n",
    "        mean=lrraw.iloc[j]['prediction_prob_high'][i][:,1].mean()\n",
    "        std=lrraw.iloc[j]['prediction_prob_high'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=lrraw.iloc[j]['prediction_prob_mid'][i][:,1].mean()\n",
    "        std=lrraw.iloc[j]['prediction_prob_mid'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrraw.iloc[j]['prediction_prob_low'][i][:,1].mean()\n",
    "        std=lrraw.iloc[j]['prediction_prob_low'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrraw.iloc[j]['prediction_prob_random'][i][:,1].mean()\n",
    "        std=lrraw.iloc[j]['prediction_prob_random'][i][:,1].std()\n",
    "        skew=stats.skew(lrraw.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrraw.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_lrraw_summary=np.asarray(high_summary)\n",
    "mid_lrraw_summary=np.asarray(mid_summary)\n",
    "low_lrraw_summary=np.asarray(low_summary)\n",
    "random_lrraw_summary=np.asarray(random_summary)\n",
    "summaries_lrraw=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of probability of high engagement classification over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(lrlmu)):\n",
    "    for i in range(18):\n",
    "        mean=lrlmu.iloc[j]['prediction_prob_high'][i][:,1].mean()\n",
    "        std=lrlmu.iloc[j]['prediction_prob_high'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu.iloc[j]['prediction_prob_high'][i][:,1])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=lrlmu.iloc[j]['prediction_prob_mid'][i][:,1].mean()\n",
    "        std=lrlmu.iloc[j]['prediction_prob_mid'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu.iloc[j]['prediction_prob_mid'][i][:,1])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrlmu.iloc[j]['prediction_prob_low'][i][:,1].mean()\n",
    "        std=lrlmu.iloc[j]['prediction_prob_low'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu.iloc[j]['prediction_prob_low'][i][:,1])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=lrlmu.iloc[j]['prediction_prob_random'][i][:,1].mean()\n",
    "        std=lrlmu.iloc[j]['prediction_prob_random'][i][:,1].std()\n",
    "        skew=stats.skew(lrlmu.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        kurtosis=stats.kurtosis(lrlmu.iloc[j]['prediction_prob_random'][i][:,1])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_lrlmu_summary=np.asarray(high_summary)\n",
    "mid_lrlmu_summary=np.asarray(mid_summary)\n",
    "low_lrlmu_summary=np.asarray(low_summary)\n",
    "random_lrlmu_summary=np.asarray(random_summary)\n",
    "summaries_lrlmu=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP without LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of the decision values over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(mlpraw)):\n",
    "    for i in range(18):\n",
    "        mean=mlpraw.iloc[j]['decision_high'][i][:,0].mean()\n",
    "        std=mlpraw.iloc[j]['decision_high'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw.iloc[j]['decision_high'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw.iloc[j]['decision_high'][i][:,0])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=mlpraw.iloc[j]['decision_mid'][i][:,0].mean()\n",
    "        std=mlpraw.iloc[j]['decision_mid'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw.iloc[j]['decision_mid'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw.iloc[j]['decision_mid'][i][:,0])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlpraw.iloc[j]['decision_low'][i][:,0].mean()\n",
    "        std=mlpraw.iloc[j]['decision_low'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw.iloc[j]['decision_low'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw.iloc[j]['decision_low'][i][:,0])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlpraw.iloc[j]['decision_random'][i][:,0].mean()\n",
    "        std=mlpraw.iloc[j]['decision_random'][i][:,0].std()\n",
    "        skew=stats.skew(mlpraw.iloc[j]['decision_random'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlpraw.iloc[j]['decision_random'][i][:,0])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_mlpraw_summary=np.asarray(high_summary)\n",
    "mid_mlpraw_summary=np.asarray(mid_summary)\n",
    "low_mlpraw_summary=np.asarray(low_summary)\n",
    "random_mlpraw_summary=np.asarray(random_summary)\n",
    "summaries_mlpraw=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP with LMUs. <br>\n",
    "Get mean, std, skewness and kurtosis of the decision values over each clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_summary=[]\n",
    "mid_summary=[]\n",
    "low_summary=[]\n",
    "random_summary=[]\n",
    "\n",
    "summaries=[]\n",
    "\n",
    "for j in range(len(mlplmu)):\n",
    "    for i in range(18):\n",
    "        mean=mlplmu.iloc[j]['decision_high'][i][:,0].mean()\n",
    "        std=mlplmu.iloc[j]['decision_high'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu.iloc[j]['decision_high'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu.iloc[j]['decision_high'][i][:,0])\n",
    "        label='high'\n",
    "        high_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(52):\n",
    "        mean=mlplmu.iloc[j]['decision_mid'][i][:,0].mean()\n",
    "        std=mlplmu.iloc[j]['decision_mid'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu.iloc[j]['decision_mid'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu.iloc[j]['decision_mid'][i][:,0])\n",
    "        label='mid'\n",
    "        mid_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlplmu.iloc[j]['decision_low'][i][:,0].mean()\n",
    "        std=mlplmu.iloc[j]['decision_low'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu.iloc[j]['decision_low'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu.iloc[j]['decision_low'][i][:,0])\n",
    "        label='low'\n",
    "        low_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "    for i in range(18):\n",
    "        mean=mlplmu.iloc[j]['decision_random'][i][:,0].mean()\n",
    "        std=mlplmu.iloc[j]['decision_random'][i][:,0].std()\n",
    "        skew=stats.skew(mlplmu.iloc[j]['decision_random'][i][:,0])\n",
    "        kurtosis=stats.kurtosis(mlplmu.iloc[j]['decision_random'][i][:,0])\n",
    "        label='random'\n",
    "        random_summary.append([mean,std,skew,kurtosis])\n",
    "        summaries.append([mean,std,skew,kurtosis,label])\n",
    "        \n",
    "high_mlplmu_summary=np.asarray(high_summary)\n",
    "mid_mlplmu_summary=np.asarray(mid_summary)\n",
    "low_mlplmu_summary=np.asarray(low_summary)\n",
    "random_mlplmu_summary=np.asarray(random_summary)\n",
    "summaries_mlplmu=np.asarray(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the distribution of mean classification per clip. <br>\n",
    "Also calculate the percentage of clips which were given the correct classification. <br>\n",
    "For high engagement clips, correct = 1. <br>\n",
    "For low engagement, correct = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = classifier output, y-axis = count\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "outer = gridspec.GridSpec(2, 2)\n",
    "lrrplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[0])\n",
    "lrlplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[1])\n",
    "mlprplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[2])\n",
    "mlplplot = gridspec.GridSpecFromSubplotSpec(1, 2, subplot_spec=outer[3])\n",
    "\n",
    "fig.text(0.29, 0.94, 'Logistic Regression', ha='center', fontsize=15)\n",
    "ax1 = fig.add_subplot(lrrplot[0, 0])\n",
    "ax1.hist(high_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High')\n",
    "ax1.set_ylabel('Count', fontsize=13)\n",
    "ax2 = fig.add_subplot(lrrplot[0, 1], sharey=ax1)\n",
    "ax2.hist(low_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Low')\n",
    "plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.3, 0.51, 'Probability of High Engagement', ha='center', fontsize=13)\n",
    "\n",
    "fig.text(0.77, 0.94, 'Logistic Regression with LMUs', ha='center', fontsize=15)\n",
    "ax3 = fig.add_subplot(lrlplot[0, 0])\n",
    "ax3.hist(high_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('High')\n",
    "ax3.set_ylabel('Count', fontsize=13)\n",
    "ax4 = fig.add_subplot(lrlplot[0, 1], sharey=ax3)\n",
    "ax4.hist(low_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Low')\n",
    "plt.setp(ax4.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.77, 0.51, 'Probability of High Engagement', ha='center', fontsize=13)\n",
    "\n",
    "fig.text(0.29, 0.46, 'MLP', ha='center', fontsize=15)\n",
    "ax5 = fig.add_subplot(mlprplot[0, 0])\n",
    "ax5.hist(high_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax5.title.set_text('High')\n",
    "ax5.set_ylabel('Count', fontsize=13)\n",
    "ax6 = fig.add_subplot(mlprplot[0, 1], sharey=ax5)\n",
    "ax6.hist(low_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax6.title.set_text('Low')\n",
    "plt.setp(ax6.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.29, 0.05, 'Decision Score', ha='center', fontsize=13)\n",
    "\n",
    "fig.text(0.77, 0.46, 'MLP with LMUs', ha='center', fontsize=15)\n",
    "ax7 = fig.add_subplot(mlplplot[0, 0])\n",
    "ax7.hist(high_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax7.title.set_text('High')\n",
    "ax7.set_ylabel('Count', fontsize=13)\n",
    "ax8 = fig.add_subplot(mlplplot[0, 1], sharey=ax7)\n",
    "ax8.hist(low_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax8.title.set_text('Low')\n",
    "plt.setp(ax8.get_yticklabels(), visible=False)\n",
    "\n",
    "fig.text(0.77, 0.05, 'Decision Score', ha='center', fontsize=13)\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "fig.text(0.07, 0.9, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.9, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.07, 0.44, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.44, 'D', ha='center', fontsize=15)\n",
    "\n",
    "fig.savefig('../Figs/cliphist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate mean percent of high and low frames classified correctly by each approach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(high_lrraw_summary[start:end,0]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    end+=18\n",
    "    start+=18\n",
    "        \n",
    "mid_counts=[]\n",
    "start=0\n",
    "end=52\n",
    "for j in range(20):\n",
    "    (nm, bins, plot) = ax1.hist(np.vstack(mid_lrraw_summary[start:end,0]), bins=bins)\n",
    "    mid_counts.append(nm)\n",
    "    end+=52\n",
    "    start+=52\n",
    "    \n",
    "low_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nl, bins, plot) = ax1.hist(np.vstack(low_lrraw_summary[start:end,0]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    end+=18\n",
    "    start+=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cor = [item[9] for item in high_counts] #no. high clips classified correctly in each experiment\n",
    "high_len = [sum(item) for item in high_counts] #no. high clips total in each experiment (18)\n",
    "\n",
    "mid_cor = [(item[1]+item[2]+item[3]+item[4]+item[5]+item[6]+item[7]+item[8]) for item in mid_counts] #no. mid clips classified correctly in each experiment\n",
    "mid_len = [sum(item) for item in mid_counts] #no. mid clips total in each experiment (52)\n",
    "\n",
    "low_cor = [item[0] for item in low_counts] #no. low clips classified correctly in each experiment\n",
    "low_len = [sum(item) for item in low_counts] #no. low clips total in each experiment (18)\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "mid_percent=[]\n",
    "low_percent=[]\n",
    "lrr_percentcorrect=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    mid_percent.append((mid_cor[i]/mid_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    lrr_percentcorrect.append((high_cor[i]+low_cor[i])/(high_len[i]+low_len[i]))\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "mid_percent=np.asarray(mid_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "lrrhigh_cor_mean=high_percent.mean()\n",
    "lrrhigh_cor_sd=high_percent.std()\n",
    "lrrmid_cor_mean=mid_percent.mean()\n",
    "lrrmid_cor_sd=mid_percent.std()\n",
    "lrrlow_cor_mean=low_percent.mean()\n",
    "lrrlow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(high_lrlmu_summary[start:end,0]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    end+=18\n",
    "    start+=18\n",
    "        \n",
    "mid_counts=[]\n",
    "start=0\n",
    "end=52\n",
    "for j in range(20):\n",
    "    (nm, bins, plot) = ax1.hist(np.vstack(mid_lrlmu_summary[start:end,0]), bins=bins)\n",
    "    mid_counts.append(nm)\n",
    "    end+=52\n",
    "    start+=52\n",
    "    \n",
    "low_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nl, bins, plot) = ax1.hist(np.vstack(low_lrlmu_summary[start:end,0]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    end+=18\n",
    "    start+=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cor = [item[9] for item in high_counts] #no. high clips classified correctly in each experiment\n",
    "high_len = [sum(item) for item in high_counts] #no. high clips total in each experiment (18)\n",
    "\n",
    "mid_cor = [(item[1]+item[2]+item[3]+item[4]+item[5]+item[6]+item[7]+item[8]) for item in mid_counts] #no. mid clips classified correctly in each experiment\n",
    "mid_len = [sum(item) for item in mid_counts] #no. mid clips total in each experiment (52)\n",
    "\n",
    "low_cor = [item[0] for item in low_counts] #no. low clips classified correctly in each experiment\n",
    "low_len = [sum(item) for item in low_counts] #no. low clips total in each experiment (18)\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "mid_percent=[]\n",
    "low_percent=[]\n",
    "lrl_percentcorrect=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    mid_percent.append((mid_cor[i]/mid_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    lrl_percentcorrect.append((high_cor[i]+low_cor[i])/(high_len[i]+low_len[i]))\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "mid_percent=np.asarray(mid_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "lrlmuhigh_cor_mean=high_percent.mean()\n",
    "lrlmuhigh_cor_sd=high_percent.std()\n",
    "lrlmumid_cor_mean=mid_percent.mean()\n",
    "lrlmumid_cor_sd=mid_percent.std()\n",
    "lrlmulow_cor_mean=low_percent.mean()\n",
    "lrlmulow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP without LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(high_mlpraw_summary[start:end,0]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    end+=18\n",
    "    start+=18\n",
    "        \n",
    "mid_counts=[]\n",
    "start=0\n",
    "end=52\n",
    "for j in range(20):\n",
    "    (nm, bins, plot) = ax1.hist(np.vstack(mid_mlpraw_summary[start:end,0]), bins=bins)\n",
    "    mid_counts.append(nm)\n",
    "    end+=52\n",
    "    start+=52\n",
    "    \n",
    "low_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nl, bins, plot) = ax1.hist(np.vstack(low_mlpraw_summary[start:end,0]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    end+=18\n",
    "    start+=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cor = [item[9] for item in high_counts] #no. high clips classified correctly in each experiment\n",
    "high_len = [sum(item) for item in high_counts] #no. high clips total in each experiment (18)\n",
    "\n",
    "mid_cor = [(item[1]+item[2]+item[3]+item[4]+item[5]+item[6]+item[7]+item[8]) for item in mid_counts] #no. mid clips classified correctly in each experiment\n",
    "mid_len = [sum(item) for item in mid_counts] #no. mid clips total in each experiment (52)\n",
    "\n",
    "low_cor = [item[0] for item in low_counts] #no. low clips classified correctly in each experiment\n",
    "low_len = [sum(item) for item in low_counts] #no. low clips total in each experiment (18)\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "mid_percent=[]\n",
    "low_percent=[]\n",
    "mlpr_percentcorrect=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    mid_percent.append((mid_cor[i]/mid_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    mlpr_percentcorrect.append((high_cor[i]+low_cor[i])/(high_len[i]+low_len[i]))\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "mid_percent=np.asarray(mid_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "mlprhigh_cor_mean=high_percent.mean()\n",
    "mlprhigh_cor_sd=high_percent.std()\n",
    "mlprmid_cor_mean=mid_percent.mean()\n",
    "mlprmid_cor_sd=mid_percent.std()\n",
    "mlprlow_cor_mean=low_percent.mean()\n",
    "mlprlow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP with LMUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nh, bins, plot) = ax1.hist(np.vstack(high_mlplmu_summary[start:end,0]), bins=bins)\n",
    "    high_counts.append(nh)\n",
    "    end+=18\n",
    "    start+=18\n",
    "        \n",
    "mid_counts=[]\n",
    "start=0\n",
    "end=52\n",
    "for j in range(20):\n",
    "    (nm, bins, plot) = ax1.hist(np.vstack(mid_mlplmu_summary[start:end,0]), bins=bins)\n",
    "    mid_counts.append(nm)\n",
    "    end+=52\n",
    "    start+=52\n",
    "    \n",
    "low_counts=[]\n",
    "start=0\n",
    "end=18\n",
    "for j in range(20):\n",
    "    (nl, bins, plot) = ax1.hist(np.vstack(low_mlplmu_summary[start:end,0]), bins=bins)\n",
    "    low_counts.append(nl)\n",
    "    end+=18\n",
    "    start+=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cor = [item[9] for item in high_counts] #no. high clips classified correctly in each experiment\n",
    "high_len = [sum(item) for item in high_counts] #no. high clips total in each experiment (18)\n",
    "\n",
    "mid_cor = [(item[1]+item[2]+item[3]+item[4]+item[5]+item[6]+item[7]+item[8]) for item in mid_counts] #no. mid clips classified correctly in each experiment\n",
    "mid_len = [sum(item) for item in mid_counts] #no. mid clips total in each experiment (52)\n",
    "\n",
    "low_cor = [item[0] for item in low_counts] #no. low clips classified correctly in each experiment\n",
    "low_len = [sum(item) for item in low_counts] #no. low clips total in each experiment (18)\n",
    "\n",
    "#Calculate percent correct in each experiment for each class (3 lists of 20 percentages)\n",
    "high_percent=[]\n",
    "mid_percent=[]\n",
    "low_percent=[]\n",
    "mlpl_percentcorrect=[]\n",
    "for i in range(20):\n",
    "    high_percent.append((high_cor[i]/high_len[i])*100)\n",
    "    mid_percent.append((mid_cor[i]/mid_len[i])*100)\n",
    "    low_percent.append((low_cor[i]/low_len[i])*100)\n",
    "    mlpl_percentcorrect.append((high_cor[i]+low_cor[i])/(high_len[i]+low_len[i]))\n",
    "    \n",
    "high_percent=np.asarray(high_percent)\n",
    "mid_percent=np.asarray(mid_percent)\n",
    "low_percent=np.asarray(low_percent)\n",
    "\n",
    "#Calculate mean percent correct and standard deviation for each clip type\n",
    "mlplmuhigh_cor_mean=high_percent.mean()\n",
    "mlplmuhigh_cor_sd=high_percent.std()\n",
    "mlplmumid_cor_mean=mid_percent.mean()\n",
    "mlplmumid_cor_sd=mid_percent.std()\n",
    "mlplmulow_cor_mean=low_percent.mean()\n",
    "mlplmulow_cor_sd=low_percent.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Percent_Correct_Clips = pd.DataFrame({'LR w/o LMU M(SD)': [f'{lrrhigh_cor_mean:.2f}'+'%'+' ('+f'{lrrhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{lrrmid_cor_mean:.2f}'+'%'+' ('+f'{lrrmid_cor_sd:.2f}'+')',\n",
    "                                                  f'{lrrlow_cor_mean:.2f}'+'%'+' ('+f'{lrrlow_cor_sd:.2f}'+')'],\n",
    "                                'LR with LMU M(SD)': [f'{lrlmuhigh_cor_mean:.2f}'+'%'+' ('+f'{lrlmuhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{lrlmumid_cor_mean:.2f}'+'%'+' ('+f'{lrlmumid_cor_sd:.2f}'+')',\n",
    "                                                  f'{lrlmulow_cor_mean:.2f}'+'%'+' ('+f'{lrlmulow_cor_sd:.2f}'+')'],\n",
    "                                'MLP w/o LMU M(SD)': [f'{mlprhigh_cor_mean:.2f}'+'%'+' ('+f'{mlprhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{mlprmid_cor_mean:.2f}'+'%'+' ('+f'{mlprmid_cor_sd:.2f}'+')',\n",
    "                                                  f'{mlprlow_cor_mean:.2f}'+'%'+' ('+f'{mlprlow_cor_sd:.2f}'+')'],\n",
    "                                'MLP with LMU M(SD)': [f'{mlplmuhigh_cor_mean:.2f}'+'%'+' ('+f'{mlplmuhigh_cor_sd:.2f}'+')',\n",
    "                                                  f'{mlplmumid_cor_mean:.2f}'+'%'+' ('+f'{mlplmumid_cor_sd:.2f}'+')',\n",
    "                                                  f'{mlplmulow_cor_mean:.2f}'+'%'+' ('+f'{mlplmulow_cor_sd:.2f}'+')']})\n",
    "\n",
    "Percent_Correct_Clips.set_index([pd.Index(['High Engagement', 'Intermediate Engagement', 'Low Engagement'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of classifier type and LMU pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-way ANOVA with classifier (Logistic Regression vs. MLP) and Pre-processing (with vs. without LMU) <br>\n",
    "Dependent Variable (outcome) = percent of high and low engagement clips classified correctly in each experiment. <br>\n",
    "Independent Variables = classifier and pre-processing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_percentcorrect=pd.DataFrame(lrr_percentcorrect)\n",
    "lrr_percentcorrect['classifier']='classifier1'\n",
    "lrr_percentcorrect['preprocess']='preprocess1'\n",
    "\n",
    "lrl_percentcorrect=pd.DataFrame(lrl_percentcorrect)\n",
    "lrl_percentcorrect['classifier']='classifier1'\n",
    "lrl_percentcorrect['preprocess']='preprocess2'\n",
    "\n",
    "mlpr_percentcorrect=pd.DataFrame(mlpr_percentcorrect)\n",
    "mlpr_percentcorrect['classifier']='classifier2'\n",
    "mlpr_percentcorrect['preprocess']='preprocess1'\n",
    "\n",
    "mlpl_percentcorrect=pd.DataFrame(mlpl_percentcorrect)\n",
    "mlpl_percentcorrect['classifier']='classifier2'\n",
    "mlpl_percentcorrect['preprocess']='preprocess2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data=lrr_percentcorrect.append(lrl_percentcorrect)\n",
    "stacked_data=stacked_data.append(mlpr_percentcorrect)\n",
    "stacked_data=stacked_data.append(mlpl_percentcorrect)\n",
    "\n",
    "stacked_data = stacked_data.rename(columns={0:'result'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ANOVA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols('result ~ classifier*preprocess', stacked_data).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumption Checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapiro's test for normality - testing the residuals. If not significant the residuals are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(results.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bartlett's test for equal variances between groups. If not significant the groups have equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.bartlett(stacked_data['result'][(stacked_data['classifier'] == 'classifier1') & (stacked_data['preprocess'] == 'preprocess1')],\n",
    "             stacked_data['result'][(stacked_data['classifier'] == 'classifier1') & (stacked_data['preprocess'] == 'preprocess2')],\n",
    "             stacked_data['result'][(stacked_data['classifier'] == 'classifier2') & (stacked_data['preprocess'] == 'preprocess1')],\n",
    "             stacked_data['result'][(stacked_data['classifier'] == 'classifier2') & (stacked_data['preprocess'] == 'preprocess2')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two-way ANOVA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(stacked_data.groupby(['classifier']))['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(stacked_data.groupby(['preprocess']))['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(stacked_data.groupby(['classifier', 'preprocess']))['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aov_table = sm.stats.anova_lm(results, typ=2)\n",
    "\n",
    "def anova_table(aov):\n",
    "    aov['mean_sq'] = aov[:]['sum_sq']/aov[:]['df']\n",
    "    \n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    \n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*aov['mean_sq'][-1]))/(sum(aov['sum_sq'])+aov['mean_sq'][-1])\n",
    "    \n",
    "    cols = ['sum_sq', 'df', 'mean_sq', 'F', 'PR(>F)', 'eta_sq', 'omega_sq']\n",
    "    aov = aov[cols]\n",
    "    return aov\n",
    "\n",
    "anova_table(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = statsmodels.stats.multicomp.MultiComparison(stacked_data['result'], stacked_data['classifier'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = statsmodels.stats.multicomp.MultiComparison(stacked_data['result'], stacked_data['preprocess'])\n",
    "mc_results = mc.tukeyhsd()\n",
    "print(mc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on Untrained Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the mean output of each test clip in all 20 experiments\n",
    "bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "#plot histograms - x-axis = classifier output, y-axis = count\n",
    "fig = plt.figure(figsize=(15, 16))\n",
    "outer = gridspec.GridSpec(4, 4)\n",
    "\n",
    "fig.text(0.52, 0.97, 'Logistic Regression', ha='center', fontsize=15)\n",
    "ax1 = fig.add_subplot(outer[0])\n",
    "ax1.hist(high_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax1.title.set_text('High Test Clips')\n",
    "ax1.set_ylabel('Count', fontsize=14)\n",
    "ax2 = fig.add_subplot(outer[1], sharey=ax1)\n",
    "ax2.hist(mid_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax2.title.set_text('Intermediate Test Clips')\n",
    "ax3 = fig.add_subplot(outer[2], sharey=ax1)\n",
    "ax3.hist(low_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax3.title.set_text('Low Test Clips')\n",
    "ax4 = fig.add_subplot(outer[3], sharey=ax1)\n",
    "ax4.hist(random_lrraw_summary[:,0], bins=bins, color='black')\n",
    "ax4.title.set_text('Random Test Clips')\n",
    "\n",
    "fig.text(0.52, 0.73, 'Logistic Regression with LMUs', ha='center', fontsize=15)\n",
    "ax5 = fig.add_subplot(outer[4])\n",
    "ax5.hist(high_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax5.title.set_text('High Test Clips')\n",
    "ax5.set_ylabel('Count', fontsize=14)\n",
    "ax6 = fig.add_subplot(outer[5], sharey=ax5)\n",
    "ax6.hist(mid_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax6.title.set_text('Intermediate Test Clips')\n",
    "ax7 = fig.add_subplot(outer[6], sharey=ax5)\n",
    "ax7.hist(low_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax7.title.set_text('Low Test Clips')\n",
    "ax8 = fig.add_subplot(outer[7], sharey=ax5)\n",
    "ax8.hist(random_lrlmu_summary[:,0], bins=bins, color='black')\n",
    "ax8.title.set_text('Random Test Clips')\n",
    "\n",
    "fig.text(0.52, 0.49, 'MLP', ha='center', fontsize=15)\n",
    "ax9 = fig.add_subplot(outer[8])\n",
    "ax9.hist(high_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax9.title.set_text('High Test Clips')\n",
    "ax9.set_ylabel('Count', fontsize=14)\n",
    "ax10 = fig.add_subplot(outer[9], sharey=ax9)\n",
    "ax10.hist(mid_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax10.title.set_text('Intermediate Test Clips')\n",
    "ax11 = fig.add_subplot(outer[10], sharey=ax9)\n",
    "ax11.hist(low_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax11.title.set_text('Low Test Clips')\n",
    "ax12 = fig.add_subplot(outer[11], sharey=ax1)\n",
    "ax12.hist(random_mlpraw_summary[:,0], bins=bins, color='black')\n",
    "ax12.title.set_text('Random Test Clips')\n",
    "\n",
    "fig.text(0.52, 0.25, 'MLP with LMUs', ha='center', fontsize=15)\n",
    "ax13 = fig.add_subplot(outer[12])\n",
    "ax13.hist(high_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax13.title.set_text('High Test Clips')\n",
    "ax13.set_ylabel('Count', fontsize=14)\n",
    "ax14 = fig.add_subplot(outer[13], sharey=ax13)\n",
    "ax14.hist(mid_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax14.title.set_text('Intermediate Test Clips')\n",
    "ax15 = fig.add_subplot(outer[14], sharey=ax13)\n",
    "ax15.hist(low_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax15.title.set_text('Low Test Clips')\n",
    "ax16 = fig.add_subplot(outer[15], sharey=ax13)\n",
    "ax16.hist(random_mlplmu_summary[:,0], bins=bins, color='black')\n",
    "ax16.title.set_text('Random Test Clips')\n",
    "\n",
    "fig.text(0.07, 0.95, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.07, 0.71, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.07, 0.47, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.07, 0.23, 'D', ha='center', fontsize=15)\n",
    "\n",
    "fig.tight_layout(pad=5.0)\n",
    "fig.savefig('../Figs/allcliphist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifier Output Across Clip Timeline** <br>\n",
    "Plotting the outputs of the classifier for every frame of the first 18 clips of each class, across the timeline of that clip, for the first experiment of each approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 16))\n",
    "outer = gridspec.GridSpec(2, 2)\n",
    "lrrplot = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[0])\n",
    "lrlplot = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[1])\n",
    "mlprplot = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[2])\n",
    "mlplplot = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[3])\n",
    "\n",
    "for i in range(18): # for each clip plot 1 line\n",
    "#LOGISTIC REGRESSION WITHOUT LMUS\n",
    "    ax1 = fig.add_subplot(lrrplot[0, 0])\n",
    "    a=lrraw.iloc[0]['prediction_prob_high'][i]\n",
    "    ax1.plot(a[:,1])\n",
    "    ax1.set_xlim(0,1000)\n",
    "    ax1.title.set_text('High Clips')\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax2 = fig.add_subplot(lrrplot[1, 0])\n",
    "    b=lrraw.iloc[0]['prediction_prob_mid'][i]\n",
    "    ax2.plot(b[:,1])\n",
    "    ax2.set_xlim(0,1000)\n",
    "    ax2.set_ylabel('of        High', fontsize=14)\n",
    "    ax2.title.set_text('Intermediate Clips')\n",
    "    plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax3 = fig.add_subplot(lrrplot[2, 0])\n",
    "    c=lrraw.iloc[0]['prediction_prob_low'][i]\n",
    "    ax3.plot(c[:,1])\n",
    "    ax3.set_xlim(0,1000)\n",
    "    ax3.set_ylabel('Probability', fontsize=14)\n",
    "    ax3.title.set_text('Low Clips')\n",
    "    plt.setp(ax3.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax4 = fig.add_subplot(lrrplot[3, 0])\n",
    "    d=lrraw.iloc[0]['prediction_prob_random'][i]\n",
    "    ax4.plot(d[:,1])\n",
    "    ax4.set_xlim(0,1000)\n",
    "    ax4.set_xlabel('Frame', fontsize=14)\n",
    "    ax4.title.set_text('Random Clips')\n",
    "    \n",
    "# LOGISTIC REGRESSION WITH LMUS\n",
    "    ax5 = fig.add_subplot(lrlplot[0, 0])\n",
    "    e=lrlmu.iloc[0]['prediction_prob_high'][i]\n",
    "    ax5.plot(e[:,1])\n",
    "    ax5.set_xlim(0,1000)\n",
    "    ax5.title.set_text('High Clips')\n",
    "    plt.setp(ax5.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax6 = fig.add_subplot(lrlplot[1, 0])\n",
    "    f=lrlmu.iloc[0]['prediction_prob_mid'][i]\n",
    "    ax6.plot(f[:,1])\n",
    "    ax6.set_xlim(0,1000)\n",
    "    ax6.set_ylabel('of        High', fontsize=14)\n",
    "    ax6.title.set_text('Intermediate Clips')\n",
    "    plt.setp(ax6.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax7 = fig.add_subplot(lrlplot[2, 0])\n",
    "    g=lrlmu.iloc[0]['prediction_prob_low'][i]\n",
    "    ax7.plot(g[:,1])\n",
    "    ax7.set_xlim(0,1000)\n",
    "    ax7.set_ylabel('Probability', fontsize=14)\n",
    "    ax7.title.set_text('Low Clips')\n",
    "    plt.setp(ax7.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax8 = fig.add_subplot(lrlplot[3, 0])\n",
    "    h=lrlmu.iloc[0]['prediction_prob_random'][i]\n",
    "    ax8.plot(h[:,1])\n",
    "    ax8.set_xlim(0,1000)\n",
    "    ax8.set_xlabel('Frame', fontsize=14)\n",
    "    ax8.title.set_text('Random Clips')\n",
    "\n",
    "# MLP WITHOUT LMUS\n",
    "    ax9 = fig.add_subplot(mlprplot[0, 0])\n",
    "    q=mlpraw.iloc[0]['decision_high'][i]\n",
    "    ax9.plot(q[:,0])\n",
    "    ax9.set_xlim(0,1000)\n",
    "    ax9.title.set_text('High Clips')\n",
    "    plt.setp(ax9.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax10 = fig.add_subplot(mlprplot[1, 0])\n",
    "    j=mlpraw.iloc[0]['decision_mid'][i]\n",
    "    ax10.plot(j[:,0])\n",
    "    ax10.set_xlim(0,1000)\n",
    "    ax10.set_ylabel('Value', fontsize=14)\n",
    "    ax10.title.set_text('Intermediate Clips')\n",
    "    plt.setp(ax10.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax11 = fig.add_subplot(mlprplot[2, 0])\n",
    "    k=mlpraw.iloc[0]['decision_low'][i]\n",
    "    ax11.plot(k[:,0])\n",
    "    ax11.set_xlim(0,1000)\n",
    "    ax11.set_ylabel('Decision', fontsize=14)\n",
    "    ax11.title.set_text('Low Clips')\n",
    "    plt.setp(ax11.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax12 = fig.add_subplot(mlprplot[3, 0])\n",
    "    l=mlpraw.iloc[0]['decision_random'][i]\n",
    "    ax12.plot(l[:,0])\n",
    "    ax12.set_xlim(0,1000)\n",
    "    ax12.set_xlabel('Frame', fontsize=14)\n",
    "    ax12.title.set_text('Random Clips')\n",
    "    \n",
    "# MLP WITH LMUS\n",
    "    ax13 = fig.add_subplot(mlplplot[0, 0])\n",
    "    m=mlplmu.iloc[0]['decision_high'][i]\n",
    "    ax13.plot(m[:,0])\n",
    "    ax13.set_xlim(0,1000)\n",
    "    ax13.title.set_text('High Clips')\n",
    "    plt.setp(ax13.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax14 = fig.add_subplot(mlplplot[1, 0])\n",
    "    n=mlplmu.iloc[0]['decision_mid'][i]\n",
    "    ax14.plot(n[:,0])\n",
    "    ax14.set_xlim(0,1000)\n",
    "    ax14.set_ylabel('Value', fontsize=14)\n",
    "    ax14.title.set_text('Intermediate Clips')\n",
    "    plt.setp(ax14.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax15 = fig.add_subplot(mlplplot[2, 0])\n",
    "    o=mlplmu.iloc[0]['decision_low'][i]\n",
    "    ax15.plot(o[:,0])\n",
    "    ax15.set_xlim(0,1000)\n",
    "    ax15.set_ylabel('Decision', fontsize=14)\n",
    "    ax15.title.set_text('Low Clips')\n",
    "    plt.setp(ax15.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax16 = fig.add_subplot(mlplplot[3, 0])\n",
    "    p=mlplmu.iloc[0]['decision_random'][i]\n",
    "    ax16.plot(p[:,0])\n",
    "    ax16.set_xlim(0,1000)\n",
    "    ax16.set_xlabel('Frame', fontsize=14)\n",
    "    ax16.title.set_text('Random Clips')\n",
    "    \n",
    "fig.text(0.28, 0.97, 'Logistic Regression', ha='center', fontsize=15)\n",
    "fig.text(0.75, 0.97, 'Logistic Regression with LMUs', ha='center', fontsize=15)\n",
    "fig.text(0.28, 0.49, 'MLP', ha='center', fontsize=15)\n",
    "fig.text(0.75, 0.49, 'MLP with LMUs', ha='center', fontsize=15)\n",
    "\n",
    "fig.text(0.05, 0.95, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.95, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.05, 0.47, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.47, 'D', ha='center', fontsize=15)\n",
    "\n",
    "fig.tight_layout(pad=5.0)\n",
    "fig.savefig('../Figs/timelines.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random vs. Non-Random <br>\n",
    "\n",
    "Do the random clips occupy a different region of the four-dimensional descriptive statistic space to the engagement clips?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression without LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_lrraw[start:end]\n",
    "    #get random sample of 18 high, intermediate and low clips from each experiment\n",
    "    sample = random.sample(list(exp[:88]),18)\n",
    "    sample = np.append(sample, exp[88:106],0)  \n",
    "    sample[np.where(sample =='high')]='nonrandom'\n",
    "    sample[np.where(sample =='mid')]='nonrandom'\n",
    "    sample[np.where(sample =='low')]='nonrandom'\n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "\n",
    "lrraw_r_nr=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_scores=[]\n",
    "lrr_confusion=np.zeros((20,2,2))\n",
    "\n",
    "for i in range(20):\n",
    "    X = lrraw_r_nr[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = lrraw_r_nr[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    lrr_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    lrr_confusion[i]=confusion_matrix(y, y_pred, labels=['random', 'nonrandom'])\n",
    "    \n",
    "print('Logistic Regression using mean, sd, skew and kurtosis as predictors.')\n",
    "print('Mean Score:           ', np.asarray(lrr_scores).mean())\n",
    "print('Standard Deviation:   ', np.asarray(lrr_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression with LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_lrlmu[start:end]\n",
    "    #get random sample of 18 high, intermediate and low clips from each experiment\n",
    "    sample = random.sample(list(exp[:88]),18)\n",
    "    sample = np.append(sample, exp[88:106],0)  \n",
    "    sample[np.where(sample =='high')]='nonrandom'\n",
    "    sample[np.where(sample =='mid')]='nonrandom'\n",
    "    sample[np.where(sample =='low')]='nonrandom'\n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "\n",
    "lrlmu_r_nr=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl_scores=[]\n",
    "lrl_confusion=np.zeros((20,2,2))\n",
    "\n",
    "for i in range(20):\n",
    "    X = lrlmu_r_nr[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = lrlmu_r_nr[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    lrl_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    lrl_confusion[i]=confusion_matrix(y, y_pred, labels=['random', 'nonrandom'])\n",
    "    \n",
    "print('Logistic Regression using mean, sd, skew and kurtosis as predictors.')\n",
    "print('Mean Score:           ', np.asarray(lrl_scores).mean())\n",
    "print('Standard Deviation:   ', np.asarray(lrl_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP without LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_mlpraw[start:end]\n",
    "    #get random sample of 18 high, intermediate and low clips from each experiment\n",
    "    sample = random.sample(list(exp[:88]),18)\n",
    "    sample = np.append(sample, exp[88:106],0)  \n",
    "    sample[np.where(sample =='high')]='nonrandom'\n",
    "    sample[np.where(sample =='mid')]='nonrandom'\n",
    "    sample[np.where(sample =='low')]='nonrandom'\n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "\n",
    "mlpraw_r_nr=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpr_scores=[]\n",
    "mlpr_confusion=np.zeros((20,2,2))\n",
    "\n",
    "for i in range(20):\n",
    "    X = mlpraw_r_nr[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = mlpraw_r_nr[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    mlpr_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    mlpr_confusion[i]=confusion_matrix(y, y_pred, labels=['random', 'nonrandom'])\n",
    "    \n",
    "print('Logistic Regression using mean, sd, skew and kurtosis as predictors.')\n",
    "print('Mean Score:           ', np.asarray(mlpr_scores).mean())\n",
    "print('Standard Deviation:   ', np.asarray(mlpr_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP with LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_mlplmu[start:end]\n",
    "    #get random sample of 18 high, intermediate and low clips from each experiment\n",
    "    sample = random.sample(list(exp[:88]),18)\n",
    "    sample = np.append(sample, exp[88:106],0)  \n",
    "    sample[np.where(sample =='high')]='nonrandom'\n",
    "    sample[np.where(sample =='mid')]='nonrandom'\n",
    "    sample[np.where(sample =='low')]='nonrandom'\n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "\n",
    "mlplmu_r_nr=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpl_scores=[]\n",
    "mlpl_confusion=np.zeros((20,2,2))\n",
    "\n",
    "for i in range(20):\n",
    "    X = mlplmu_r_nr[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = mlplmu_r_nr[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    mlpl_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    mlpl_confusion[i]=confusion_matrix(y, y_pred, labels=['random', 'nonrandom'])\n",
    "    \n",
    "print('Logistic Regression using mean, sd, skew and kurtosis as predictors.')\n",
    "print('Mean Score:           ', np.asarray(mlpl_scores).mean())\n",
    "print('Standard Deviation:   ', np.asarray(mlpl_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot average confusion matrix\n",
    "ticklabels=['Random', 'Non-Random']\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(15, 8))\n",
    "\n",
    "labels1=np.array([[f'{lrr_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrr_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[0][1]/18*100:.2f}'+'%)',],\n",
    "                 [f'{lrr_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrr_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[1][1]/18*100:.2f}'+'%)',]])\n",
    "im = sns.heatmap(lrr_confusion.mean(0)/20*100, annot=labels1, annot_kws={\"size\": 14}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax1)\n",
    "ax1.set_title('Logistic Regression', fontsize=14)\n",
    "im.set_yticklabels(labels=ticklabels, size = 12)\n",
    "\n",
    "labels2=np.array([[f'{lrl_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrl_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[0][1]/18*100:.2f}'+'%)',],\n",
    "                 [f'{lrl_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrl_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[1][1]/18*100:.2f}'+'%)',]])\n",
    "b = sns.heatmap(lrl_confusion.mean(0)/20*100, annot=labels2, annot_kws={\"size\": 14}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax2)\n",
    "ax2.set_title('Logistic Regression with LMUs', fontsize=14)\n",
    "\n",
    "labels3=np.array([[f'{mlpr_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpr_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[0][1]/18*100:.2f}'+'%)',],\n",
    "                 [f'{mlpr_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpr_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[1][1]/18*100:.2f}'+'%)',]])\n",
    "c=sns.heatmap(mlpr_confusion.mean(0)/20*100, annot=labels3, annot_kws={\"size\": 14}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax3)\n",
    "ax3.set_title('MLP', fontsize=14)\n",
    "c.set_yticklabels(labels=ticklabels, size = 12)\n",
    "c.set_xticklabels(labels=ticklabels, size = 12)\n",
    "\n",
    "labels4=np.array([[f'{mlpl_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpl_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[0][1]/18*100:.2f}'+'%)',],\n",
    "                 [f'{mlpl_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpl_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[1][1]/18*100:.2f}'+'%)',]])\n",
    "d = sns.heatmap(mlpl_confusion.mean(0)/20*100, annot=labels4, annot_kws={\"size\": 14}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax4)\n",
    "ax4.set_title('MLP with LMUs', fontsize=14)\n",
    "d.set_xticklabels(labels=ticklabels, size = 12)\n",
    "\n",
    "#fig.suptitle('Mean (SD) Confusion Matrices', fontsize=16)\n",
    "fig.text(0.51, 0.04, 'Predicted Label', ha='center', fontsize=14)\n",
    "fig.text(0.08, 0.44, 'True Label', ha='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "fig.text(0.11, 0.87, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.87, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.11, 0.46, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.46, 'D', ha='center', fontsize=15)\n",
    "\n",
    "mappable = im.get_children()[0]\n",
    "fig.colorbar(mappable, ax = [ax2,ax4],orientation = 'vertical')\n",
    "fig.savefig('../Figs/random_confusion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High vs. Intermediate vs. Low <br>\n",
    "\n",
    "Does each engagement class occupy a different region of the four-dimensional descriptive statistic space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression without LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_lrraw[start:end]\n",
    "    sample = exp[:18]\n",
    "    #get random sample of 18 intermediate clips from first experiment\n",
    "    sample = np.append(sample, random.sample(list(exp[exp[:,4]=='mid']),18),0) \n",
    "    sample = np.append(sample, exp[70:88],0) \n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "lrraw_in=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_scores=[]\n",
    "lrr_confusion=np.zeros((20,3,3))\n",
    "\n",
    "for i in range(20):\n",
    "    X = lrraw_in[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = lrraw_in[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    lrr_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    lrr_confusion[i]=confusion_matrix(y, y_pred, labels=['high', 'mid', 'low'])\n",
    "    \n",
    "print('kNN using mean, sd, skew and kurtosis as predictors.')\n",
    "print('Actual Mean Score:           ', np.asarray(lrr_scores).mean())\n",
    "print('Actual Standard Deviation:   ', np.asarray(lrr_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression with LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_lrlmu[start:end]\n",
    "    sample = exp[:18]\n",
    "    #get random sample of 18 intermediate clips from first experiment\n",
    "    sample = np.append(sample, random.sample(list(exp[exp[:,4]=='mid']),18),0) \n",
    "    sample = np.append(sample, exp[70:88],0) \n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "lrlmu_in=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrl_scores=[]\n",
    "lrl_confusion=np.zeros((20,3,3))\n",
    "\n",
    "for i in range(20):\n",
    "    X = lrlmu_in[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = lrlmu_in[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    lrl_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    lrl_confusion[i]=confusion_matrix(y, y_pred, labels=['high', 'mid', 'low'])\n",
    "    \n",
    "print('kNN using mean, sd, skew and kurtosis as predictors.')\n",
    "print('Actual Mean Score:           ', np.asarray(lrl_scores).mean())\n",
    "print('Actual Standard Deviation:   ', np.asarray(lrl_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP without LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_mlpraw[start:end]\n",
    "    sample = exp[:18]\n",
    "    #get random sample of 18 intermediate clips from first experiment\n",
    "    sample = np.append(sample, random.sample(list(exp[exp[:,4]=='mid']),18),0) \n",
    "    sample = np.append(sample, exp[70:88],0) \n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "mlpraw_in=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpr_scores=[]\n",
    "mlpr_confusion=np.zeros((20,3,3))\n",
    "\n",
    "for i in range(20):\n",
    "    X = mlpraw_in[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = mlpraw_in[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    mlpr_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    mlpr_confusion[i]=confusion_matrix(y, y_pred, labels=['high', 'mid', 'low'])\n",
    "    \n",
    "print('Logistic Regression using mean, sd, skewness and kurtosis as predictors.')\n",
    "print('Actual Mean Score:           ', np.asarray(mlpr_scores).mean())\n",
    "print('Actual Standard Deviation:   ', np.asarray(mlpr_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP with LMUs** <br>\n",
    "First we take 18 samples from each class in each of the 20 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    exp=summaries_mlplmu[start:end]\n",
    "    sample = exp[:18]\n",
    "    #get random sample of 18 intermediate clips from first experiment\n",
    "    sample = np.append(sample, random.sample(list(exp[exp[:,4]=='mid']),18),0) \n",
    "    sample = np.append(sample, exp[70:88],0) \n",
    "    lst.append(sample)\n",
    "    start+=106\n",
    "    end+=106\n",
    "mlplmu_in=np.asarray(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run kNN (k=5) to see how well these classes cluster based on clip mean, standard deviation, skew and kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpl_scores=[]\n",
    "mlpl_confusion=np.zeros((20,3,3))\n",
    "\n",
    "for i in range(20):\n",
    "    X = mlplmu_in[i][:,:4]\n",
    "    X = X.astype(np.float)\n",
    "    y = mlplmu_in[i][:,4]\n",
    "    \n",
    "    #clf = LogisticRegression(solver='lbfgs', multi_class='multinomial').fit(X, y)\n",
    "    clf = KNeighborsClassifier(n_neighbors=5).fit(X, y)\n",
    "    mlpl_scores.append(clf.score(X, y))\n",
    "    y_pred=clf.predict(X)\n",
    "    mlpl_confusion[i]=confusion_matrix(y, y_pred, labels=['high', 'mid', 'low'])\n",
    "    \n",
    "print('kNN using mean, sd, skewness and kurtosis as predictors.')\n",
    "print('Actual Mean Score:           ', np.asarray(mlpl_scores).mean())\n",
    "print('Actual Standard Deviation:   ', np.asarray(mlpl_scores).std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot average confusion matrix\n",
    "ticklabels=['High', 'Int', 'Low']\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(16.5, 8))\n",
    "\n",
    "labels1=np.array([[f'{lrr_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrr_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[0][1]/18*100:.2f}'+'%)',\n",
    "                  f'{lrr_confusion.mean(0)[0][2]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[0][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{lrr_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrr_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[1][1]/18*100:.2f}'+'%)',\n",
    "                 f'{lrr_confusion.mean(0)[1][2]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[1][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{lrr_confusion.mean(0)[2][0]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[2][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrr_confusion.mean(0)[2][1]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[2][1]/18*100:.2f}'+'%)',\n",
    "                 f'{lrr_confusion.mean(0)[2][2]/18*100:.2f}'+'%'+' ('+f'{lrr_confusion.std(0)[2][2]/18*100:.2f}'+'%)',]])\n",
    "im = sns.heatmap(lrr_confusion.mean(0)/20*100, annot=labels1, annot_kws={\"size\": 12}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax1)\n",
    "ax1.set_title('Logistic Regression', fontsize=14)\n",
    "im.set_yticklabels(labels=ticklabels, size = 12)\n",
    "\n",
    "labels2=np.array([[f'{lrl_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrl_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[0][1]/18*100:.2f}'+'%)',\n",
    "                  f'{lrl_confusion.mean(0)[0][2]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[0][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{lrl_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrl_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[1][1]/18*100:.2f}'+'%)',\n",
    "                 f'{lrl_confusion.mean(0)[1][2]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[1][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{lrl_confusion.mean(0)[2][0]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[2][0]/18*100:.2f}'+'%)',\n",
    "                  f'{lrl_confusion.mean(0)[2][1]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[2][1]/18*100:.2f}'+'%)',\n",
    "                 f'{lrl_confusion.mean(0)[2][2]/18*100:.2f}'+'%'+' ('+f'{lrl_confusion.std(0)[2][2]/18*100:.2f}'+'%)',]])\n",
    "b = sns.heatmap(lrl_confusion.mean(0)/20*100, annot=labels2, annot_kws={\"size\": 12}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax2)\n",
    "ax2.set_title('Logistic Regression with LMUs', fontsize=14)\n",
    "\n",
    "labels3=np.array([[f'{mlpr_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpr_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[0][1]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpr_confusion.mean(0)[0][2]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[0][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{mlpr_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpr_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[1][1]/18*100:.2f}'+'%)',\n",
    "                 f'{mlpr_confusion.mean(0)[1][2]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[1][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{mlpr_confusion.mean(0)[2][0]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[2][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpr_confusion.mean(0)[2][1]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[2][1]/18*100:.2f}'+'%)',\n",
    "                 f'{mlpr_confusion.mean(0)[2][2]/18*100:.2f}'+'%'+' ('+f'{mlpr_confusion.std(0)[2][2]/18*100:.2f}'+'%)',]])\n",
    "c=sns.heatmap(mlpr_confusion.mean(0)/20*100, annot=labels3, annot_kws={\"size\": 12}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax3)\n",
    "ax3.set_title('MLP', fontsize=14)\n",
    "c.set_yticklabels(labels=ticklabels, size = 12)\n",
    "c.set_xticklabels(labels=ticklabels, size = 12)\n",
    "\n",
    "labels4=np.array([[f'{mlpl_confusion.mean(0)[0][0]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[0][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpl_confusion.mean(0)[0][1]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[0][1]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpl_confusion.mean(0)[0][2]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[0][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{mlpl_confusion.mean(0)[1][0]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[1][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpl_confusion.mean(0)[1][1]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[1][1]/18*100:.2f}'+'%)',\n",
    "                 f'{mlpl_confusion.mean(0)[1][2]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[1][2]/18*100:.2f}'+'%)',],\n",
    "                 [f'{mlpl_confusion.mean(0)[2][0]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[2][0]/18*100:.2f}'+'%)',\n",
    "                  f'{mlpl_confusion.mean(0)[2][1]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[2][1]/18*100:.2f}'+'%)',\n",
    "                 f'{mlpl_confusion.mean(0)[2][2]/18*100:.2f}'+'%'+' ('+f'{mlpl_confusion.std(0)[2][2]/18*100:.2f}'+'%)',]])\n",
    "d = sns.heatmap(mlpl_confusion.mean(0)/20*100, annot=labels4, annot_kws={\"size\": 12}, fmt='', cmap='Blues', xticklabels=ticklabels, yticklabels=ticklabels, cbar=False, ax=ax4)\n",
    "ax4.set_title('MLP with LMUs', fontsize=14)\n",
    "d.set_xticklabels(labels=ticklabels, size = 12)\n",
    "\n",
    "#fig.suptitle('Mean (SD) Confusion Matrices', fontsize=16)\n",
    "fig.text(0.51, 0.04, 'Predicted Label', ha='center', fontsize=14)\n",
    "fig.text(0.08, 0.44, 'True Label', ha='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "fig.text(0.11, 0.87, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.87, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.11, 0.46, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.46, 'D', ha='center', fontsize=15)\n",
    "\n",
    "mappable = im.get_children()[0]\n",
    "fig.colorbar(mappable, ax = [ax2,ax4],orientation = 'vertical')\n",
    "fig.savefig('../Figs/engagement_confusion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualising the 3D kNN space - PCA Projection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the PCA on descriptive statistics of output from each approach separately. Use only output from high, intermediate and low engagement input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "\n",
    "pca_lrraw = []\n",
    "pca_lrlmu = []\n",
    "pca_mlpraw = []\n",
    "pca_mlplmu = []\n",
    "start=0\n",
    "end=106\n",
    "for i in range(20):\n",
    "    pca_lrraw.append(summaries_lrraw[start:int(start+88)])\n",
    "    pca_lrlmu.append(summaries_lrlmu[start:int(start+88)])\n",
    "    pca_mlpraw.append(summaries_mlpraw[start:int(start+88)])\n",
    "    pca_mlplmu.append(summaries_mlplmu[start:int(start+88)])\n",
    "    start += 106\n",
    "    end += 106\n",
    "pca_lrraw = np.vstack(pca_lrraw)\n",
    "pca_lrlmu = np.vstack(pca_lrlmu)\n",
    "pca_mlpraw = np.vstack(pca_mlpraw)\n",
    "pca_mlplmu = np.vstack(pca_mlplmu)\n",
    "\n",
    "X = pca_lrraw[:,:4]\n",
    "pca.fit(X)\n",
    "print('Logistic Regression without LMUs', pca.explained_variance_ratio_)\n",
    "lrrawpca_high = pca.transform(high_lrraw_summary)\n",
    "lrrawpca_mid = pca.transform(mid_lrraw_summary)\n",
    "lrrawpca_low = pca.transform(low_lrraw_summary)\n",
    "\n",
    "X = pca_lrlmu[:,:4]\n",
    "pca.fit(X)\n",
    "print('Logistic Regression with LMUs', pca.explained_variance_ratio_)\n",
    "lrlmupca_high = pca.transform(high_lrlmu_summary)\n",
    "lrlmupca_mid = pca.transform(mid_lrlmu_summary)\n",
    "lrlmupca_low = pca.transform(low_lrlmu_summary)\n",
    "\n",
    "X = pca_mlpraw[:,:4]\n",
    "pca.fit(X)\n",
    "print('MLP without LMUs', pca.explained_variance_ratio_)\n",
    "mlprawpca_high = pca.transform(high_mlpraw_summary)\n",
    "mlprawpca_mid = pca.transform(mid_mlpraw_summary)\n",
    "mlprawpca_low = pca.transform(low_mlpraw_summary)\n",
    "\n",
    "X = pca_mlplmu[:,:4]\n",
    "pca.fit(X)\n",
    "print('MLP with LMUs', pca.explained_variance_ratio_)\n",
    "mlplmupca_high = pca.transform(high_mlplmu_summary)\n",
    "mlplmupca_mid = pca.transform(mid_mlplmu_summary)\n",
    "mlplmupca_low = pca.transform(low_mlplmu_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = gridspec.GridSpec(2,2)\n",
    "\n",
    "ax1=fig.add_subplot(gs[0,0], projection='3d')\n",
    "ax1.plot(lrrawpca_high[:,1],lrrawpca_high[:,2],lrrawpca_high[:,0], linestyle='none',alpha=0.7, marker='o',markeredgecolor='black',markerfacecolor='None',label='high')\n",
    "ax1.plot(lrrawpca_mid[:,1],lrrawpca_mid[:,2],lrrawpca_mid[:,0], linestyle='none',alpha=0.7, marker='x',markeredgecolor='orange',markerfacecolor='None',label='mid')\n",
    "ax1.plot(lrrawpca_low[:,1],lrrawpca_low[:,2],lrrawpca_low[:,0], linestyle='none',alpha=0.7, marker='<',markeredgecolor='grey',markerfacecolor='None',label='low')\n",
    "ax1.set_xlabel('C2', fontsize=12)\n",
    "ax1.set_ylabel('C3', fontsize=12)\n",
    "ax1.set_zlabel('C1', fontsize=12)\n",
    "ax1.legend(loc=(0.9,0))\n",
    "ax1.set_title('Logistic Regression without LMUs', fontsize=14)\n",
    "\n",
    "ax2=fig.add_subplot(gs[0,1], projection='3d')\n",
    "ax2.plot(lrlmupca_high[:,1],lrlmupca_high[:,2],lrlmupca_high[:,0], linestyle='none',alpha=0.7, marker='o',markeredgecolor='black',markerfacecolor='None',label='high')\n",
    "ax2.plot(lrlmupca_mid[:,1],lrlmupca_mid[:,2],lrlmupca_mid[:,0], linestyle='none',alpha=0.7, marker='x',markeredgecolor='orange',markerfacecolor='None',label='mid')\n",
    "ax2.plot(lrlmupca_low[:,1],lrlmupca_low[:,2],lrlmupca_low[:,0], linestyle='none',alpha=0.7, marker='<',markeredgecolor='grey',markerfacecolor='None',label='low')\n",
    "ax2.set_xlabel('C2', fontsize=12)\n",
    "ax2.set_ylabel('C3', fontsize=12)\n",
    "ax2.set_zlabel('C1', fontsize=12)\n",
    "ax2.legend(loc=(0.9,0))\n",
    "ax2.set_title('Logistic Regression with LMUs', fontsize=14)\n",
    "\n",
    "ax3=fig.add_subplot(gs[1,0], projection='3d')\n",
    "ax3.plot(mlprawpca_high[:,1],mlprawpca_high[:,2],mlprawpca_high[:,0], linestyle='none',alpha=0.7, marker='o',markeredgecolor='black',markerfacecolor='None',label='high')\n",
    "ax3.plot(mlprawpca_mid[:,1],mlprawpca_mid[:,2],mlprawpca_mid[:,0], linestyle='none',alpha=0.7, marker='x',markeredgecolor='orange',markerfacecolor='None',label='mid')\n",
    "ax3.plot(mlprawpca_low[:,1],mlprawpca_low[:,2],mlprawpca_low[:,0], linestyle='none',alpha=0.7, marker='<',markeredgecolor='grey',markerfacecolor='None',label='low')\n",
    "ax3.set_xlabel('C2', fontsize=12)\n",
    "ax3.set_ylabel('C3', fontsize=12)\n",
    "ax3.set_zlabel('C1', fontsize=12)\n",
    "ax3.legend(loc=(0.9,0))\n",
    "ax3.set_title('MLP without LMUs', fontsize=14)\n",
    "\n",
    "ax4=fig.add_subplot(gs[1,1], projection='3d')\n",
    "ax4.plot(mlplmupca_high[:,1],mlplmupca_high[:,2],mlplmupca_high[:,0], linestyle='none',alpha=0.7, marker='o',markeredgecolor='black',markerfacecolor='None',label='high')\n",
    "ax4.plot(mlplmupca_mid[:,1],mlplmupca_mid[:,2],mlplmupca_mid[:,0], linestyle='none',alpha=0.7, marker='x',markeredgecolor='orange',markerfacecolor='None',label='mid')\n",
    "ax4.plot(mlplmupca_low[:,1],mlplmupca_low[:,2],mlplmupca_low[:,0], linestyle='none',alpha=0.7, marker='<',markeredgecolor='grey',markerfacecolor='None',label='low')\n",
    "ax4.set_xlabel('C2', fontsize=12)\n",
    "ax4.set_ylabel('C3', fontsize=12)\n",
    "ax4.set_zlabel('C1', fontsize=12)\n",
    "ax4.legend(loc=(0.9,0))\n",
    "ax4.set_title('MLP with LMUs', fontsize=14)\n",
    "\n",
    "fig.text(0.16, 0.8, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.58, 0.8, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.16, 0.39, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.58, 0.39, 'D', ha='center', fontsize=15)\n",
    "\n",
    "fig.savefig('../Figs/engagement_pca.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flattening the Line** <br>\n",
    "MLP approaches. <br>\n",
    "Create new arrays of the 3 PCA component scores for each clip with clip label denoted as 0 = high, 1 = mid, and 2 = low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((mlprawpca_high.shape[0], 1))\n",
    "x = np.hstack((mlprawpca_high, a))\n",
    "\n",
    "a = np.zeros((mlprawpca_mid.shape[0], 1))\n",
    "a = np.where(a==0, 1, a) \n",
    "y = np.hstack((mlprawpca_mid, a))\n",
    "\n",
    "a = np.zeros((mlprawpca_low.shape[0], 1))\n",
    "a = np.where(a==0, 2, a) \n",
    "z = np.hstack((mlprawpca_low, a))\n",
    "\n",
    "mlprawpca_all = np.vstack((x,y,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((mlplmupca_high.shape[0], 1))\n",
    "x = np.hstack((mlplmupca_high, a))\n",
    "\n",
    "a = np.zeros((mlplmupca_mid.shape[0], 1))\n",
    "a = np.where(a==0, 1, a) \n",
    "y = np.hstack((mlplmupca_mid, a))\n",
    "\n",
    "a = np.zeros((mlplmupca_low.shape[0], 1))\n",
    "a = np.where(a==0, 2, a) \n",
    "z = np.hstack((mlplmupca_low, a))\n",
    "\n",
    "mlplmupca_all = np.vstack((x,y,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the index for the clip with the highest score on the first component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(mlprawpca_all[:,0] == np.amax(mlprawpca_all[:,0])))\n",
    "print(np.where(mlplmupca_all[:,0] == np.amax(mlplmupca_all[:,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for sorting the clips from the 3D line onto a flat line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_list(x, start_idx):\n",
    "    \n",
    "    sortme = copy.deepcopy(x)\n",
    "    \n",
    "    #We stretch out dimension 1 since this is the dimension in which the \"knot\" takes place\n",
    "    sortme[:,1] = 100* sortme[:,1]\n",
    "        \n",
    "    start_point = sortme[start_idx,:]\n",
    "    distances = np.inf*np.ones(np.size(sortme,0))\n",
    "        \n",
    "    for idx, row in enumerate(sortme):\n",
    "        distances[idx] = np.linalg.norm(row[0:3]-start_point[0:3])  \n",
    "            \n",
    "    y = np.c_[sortme, distances]\n",
    "    y = y[y[:,4].argsort()]\n",
    "\n",
    "    y[:,1] = y[:,1]/100 #return to original coordinates\n",
    "    \n",
    "    #we want density plots to take into account the distance between individual points (rather than the distance from all points to the start point)\n",
    "    for idx, row in enumerate(y):   \n",
    "        if idx == 0:\n",
    "            y[0,4] = 0\n",
    "        else:\n",
    "            y[idx,4] = np.linalg.norm(row[0:3]-y[idx-1,0:3])  \n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = sort_list(mlprawpca_all, 1227)\n",
    "lmu = sort_list(mlplmupca_all, 357)\n",
    "\n",
    "trajectory_indexes = np.cumsum(raw[:,4])\n",
    "trajectory_indexes = trajectory_indexes/np.amax(trajectory_indexes)\n",
    "classes = raw[:,3]\n",
    "\n",
    "low_engagement_raw = trajectory_indexes[np.where(classes == 2)]\n",
    "mid_engagement_raw = trajectory_indexes[np.where(classes == 1)]\n",
    "high_engagement_raw = trajectory_indexes[np.where(classes == 0)]\n",
    "\n",
    "trajectory_indexes = np.cumsum(lmu[:,4])\n",
    "trajectory_indexes = trajectory_indexes/np.amax(trajectory_indexes)\n",
    "classes = lmu[:,3]\n",
    "\n",
    "low_engagement_lmu = trajectory_indexes[np.where(classes == 2)]\n",
    "mid_engagement_lmu = trajectory_indexes[np.where(classes == 1)]\n",
    "high_engagement_lmu = trajectory_indexes[np.where(classes == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = gridspec.GridSpec(2,2)\n",
    "\n",
    "ax1=fig.add_subplot(gs[0,0], projection='3d')#, facecolor='grey')\n",
    "ax1.scatter(raw[:,1], raw[:,2], raw[:,0], c=range(np.size(raw,0)), cmap='viridis')\n",
    "ax1.set_title('MLP without LMUs', fontsize=14)\n",
    "ax1.set_xlabel('C2', fontsize=12)\n",
    "ax1.set_ylabel('C3', fontsize=12)\n",
    "ax1.set_zlabel('C1', fontsize=12)\n",
    "\n",
    "ax2=fig.add_subplot(gs[0,1], projection='3d')#, facecolor='grey')\n",
    "ax2.scatter(lmu[:,1], lmu[:,2], lmu[:,0], c=range(np.size(lmu,0)), cmap=\"viridis\")\n",
    "ax2.set_title('MLP with LMUs', fontsize=14)\n",
    "ax2.set_xlabel('C2', fontsize=12)\n",
    "ax2.set_ylabel('C3', fontsize=12)\n",
    "ax2.set_zlabel('C1', fontsize=12)\n",
    "\n",
    "ax3=fig.add_subplot(gs[1,0])\n",
    "sns.distplot(high_engagement_raw, hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3}, label='High', ax=ax3, color='black')\n",
    "sns.distplot(mid_engagement_raw, hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3}, label='Intermediate', ax=ax3, color='orange')\n",
    "sns.distplot(low_engagement_raw, hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3}, label='Low', ax=ax3, color='lightgrey')\n",
    "ax3.set_title('MLP without LMUs', fontsize=14)\n",
    "ax3.set_xlabel('Index', fontsize=13)\n",
    "ax3.set_ylabel('Density', fontsize=13)\n",
    "\n",
    "ax4=fig.add_subplot(gs[1,1])\n",
    "sns.distplot(high_engagement_lmu, hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3}, label='High', ax=ax4, color='black'), \n",
    "sns.distplot(mid_engagement_lmu, hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3}, label='Intermediate', ax=ax4, color='orange')\n",
    "sns.distplot(low_engagement_lmu, hist = False, kde = True, kde_kws = {'shade': True, 'linewidth': 3}, label='Low', ax=ax4, color='lightgrey')\n",
    "ax4.set_title('MLP with LMUs', fontsize=14)\n",
    "ax4.set_xlabel('Index', fontsize=13)\n",
    "ax4.set_ylabel('Density', fontsize=13)\n",
    "\n",
    "fig.text(0.16, 0.8, 'A', ha='center', fontsize=15)\n",
    "fig.text(0.58, 0.8, 'B', ha='center', fontsize=15)\n",
    "fig.text(0.11, 0.46, 'C', ha='center', fontsize=15)\n",
    "fig.text(0.53, 0.46, 'D', ha='center', fontsize=15)\n",
    "\n",
    "fig.savefig('../Figs/flatten_pca.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Effect of Classifier and Pre-processing on kNN performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr_kNNscores=pd.DataFrame(lrr_scores)\n",
    "lrr_kNNscores['classifier']='classifier1'\n",
    "lrr_kNNscores['preprocess']='preprocess1'\n",
    "\n",
    "lrl_kNNscores=pd.DataFrame(lrl_scores)\n",
    "lrl_kNNscores['classifier']='classifier1'\n",
    "lrl_kNNscores['preprocess']='preprocess2'\n",
    "\n",
    "mlpr_kNNscores=pd.DataFrame(mlpr_scores)\n",
    "mlpr_kNNscores['classifier']='classifier2'\n",
    "mlpr_kNNscores['preprocess']='preprocess1'\n",
    "\n",
    "mlpl_kNNscores=pd.DataFrame(mlpl_scores)\n",
    "mlpl_kNNscores['classifier']='classifier2'\n",
    "mlpl_kNNscores['preprocess']='preprocess2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_data=lrr_kNNscores.append(lrl_kNNscores)\n",
    "stacked_data=stacked_data.append(mlpr_kNNscores)\n",
    "stacked_data=stacked_data.append(mlpl_kNNscores)\n",
    "\n",
    "stacked_data = stacked_data.rename(columns={0:'result'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ANOVA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols('result ~ classifier*preprocess', stacked_data).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assumption Checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapiro's test for normality - testing the residuals. If not significant the residuals are normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(results.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bartlett's test for equal variances between groups. If not significant the groups have equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.bartlett(stacked_data['result'][(stacked_data['classifier'] == 'classifier1') & (stacked_data['preprocess'] == 'preprocess1')],\n",
    "             stacked_data['result'][(stacked_data['classifier'] == 'classifier1') & (stacked_data['preprocess'] == 'preprocess2')],\n",
    "             stacked_data['result'][(stacked_data['classifier'] == 'classifier2') & (stacked_data['preprocess'] == 'preprocess1')],\n",
    "             stacked_data['result'][(stacked_data['classifier'] == 'classifier2') & (stacked_data['preprocess'] == 'preprocess2')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two-way ANOVA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(stacked_data.groupby(['classifier']))['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(stacked_data.groupby(['preprocess']))['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(stacked_data.groupby(['classifier', 'preprocess']))['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aov_table = sm.stats.anova_lm(results, typ=2)\n",
    "\n",
    "def anova_table(aov):\n",
    "    aov['mean_sq'] = aov[:]['sum_sq']/aov[:]['df']\n",
    "    \n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    \n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*aov['mean_sq'][-1]))/(sum(aov['sum_sq'])+aov['mean_sq'][-1])\n",
    "    \n",
    "    cols = ['sum_sq', 'df', 'mean_sq', 'F', 'PR(>F)', 'eta_sq', 'omega_sq']\n",
    "    aov = aov[cols]\n",
    "    return aov\n",
    "\n",
    "anova_table(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
